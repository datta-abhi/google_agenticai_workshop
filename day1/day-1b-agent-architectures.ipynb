{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T21:57:40.307674Z","iopub.execute_input":"2025-11-10T21:57:40.307986Z","iopub.status.idle":"2025-11-10T21:57:40.313551Z","shell.execute_reply.started":"2025-11-10T21:57:40.307935Z","shell.execute_reply":"2025-11-10T21:57:40.312426Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:23:51.718942Z","iopub.execute_input":"2025-11-11T15:23:51.719317Z","iopub.status.idle":"2025-11-11T15:23:51.835765Z","shell.execute_reply.started":"2025-11-11T15:23:51.719284Z","shell.execute_reply":"2025-11-11T15:23:51.834756Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:26:28.517484Z","iopub.execute_input":"2025-11-11T15:26:28.517737Z","iopub.status.idle":"2025-11-11T15:27:07.553391Z","shell.execute_reply.started":"2025-11-11T15:26:28.517718Z","shell.execute_reply":"2025-11-11T15:27:07.552460Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:27:45.961636Z","iopub.execute_input":"2025-11-11T15:27:45.963031Z","iopub.status.idle":"2025-11-11T15:27:45.968626Z","shell.execute_reply.started":"2025-11-11T15:27:45.963011Z","shell.execute_reply":"2025-11-11T15:27:45.967540Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:30:07.063891Z","iopub.execute_input":"2025-11-11T15:30:07.064203Z","iopub.status.idle":"2025-11-11T15:30:07.070422Z","shell.execute_reply.started":"2025-11-11T15:30:07.064184Z","shell.execute_reply":"2025-11-11T15:30:07.069395Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:30:15.555352Z","iopub.execute_input":"2025-11-11T15:30:15.555654Z","iopub.status.idle":"2025-11-11T15:30:15.561000Z","shell.execute_reply.started":"2025-11-11T15:30:15.555635Z","shell.execute_reply":"2025-11-11T15:30:15.560199Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:34:52.562235Z","iopub.execute_input":"2025-11-11T15:34:52.563083Z","iopub.status.idle":"2025-11-11T15:34:52.569734Z","shell.execute_reply.started":"2025-11-11T15:34:52.563062Z","shell.execute_reply":"2025-11-11T15:34:52.568182Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:37:14.803526Z","iopub.execute_input":"2025-11-11T15:37:14.803763Z","iopub.status.idle":"2025-11-11T15:37:23.528482Z","shell.execute_reply.started":"2025-11-11T15:37:14.803749Z","shell.execute_reply":"2025-11-11T15:37:23.527412Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > The latest advancements in quantum computing are set to revolutionize AI by significantly speeding up AI training, enabling the solution of complex problems currently beyond the reach of classical computers, and improving areas like natural language processing and data processing. Concurrently, there's notable progress in the maturation of quantum hardware and software, with a focus on developing more stable qubits, increasing qubit counts, and implementing quantum error correction. Both leading companies and national research initiatives are heavily invested in this progress. While quantum AI is expected to experience substantial growth and unlock unprecedented solutions in the coming decade, it also brings to the forefront the need to address ethical and societal implications.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:43:02.913689Z","iopub.execute_input":"2025-11-11T15:43:02.914047Z","iopub.status.idle":"2025-11-11T15:43:02.919394Z","shell.execute_reply.started":"2025-11-11T15:43:02.914023Z","shell.execute_reply":"2025-11-11T15:43:02.918441Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:43:10.428458Z","iopub.execute_input":"2025-11-11T15:43:10.428709Z","iopub.status.idle":"2025-11-11T15:43:10.434758Z","shell.execute_reply.started":"2025-11-11T15:43:10.428695Z","shell.execute_reply":"2025-11-11T15:43:10.433602Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:43:17.021017Z","iopub.execute_input":"2025-11-11T15:43:17.021315Z","iopub.status.idle":"2025-11-11T15:43:17.027592Z","shell.execute_reply.started":"2025-11-11T15:43:17.021300Z","shell.execute_reply":"2025-11-11T15:43:17.026509Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:43:28.377902Z","iopub.execute_input":"2025-11-11T15:43:28.378281Z","iopub.status.idle":"2025-11-11T15:43:28.383225Z","shell.execute_reply.started":"2025-11-11T15:43:28.378253Z","shell.execute_reply":"2025-11-11T15:43:28.382333Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:45:06.111012Z","iopub.execute_input":"2025-11-11T15:45:06.111254Z","iopub.status.idle":"2025-11-11T15:45:16.181310Z","shell.execute_reply.started":"2025-11-11T15:45:06.111220Z","shell.execute_reply":"2025-11-11T15:45:16.180452Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > ## Blog Outline:\n\n**Headline:** Level Up Your Code: How Multi-Agent Systems Can Revolutionize Software Development\n\n**Introduction Hook:** Are you tired of monolithic codebases that are a nightmare to manage and scale? Imagine a world where your software development process is more agile, robust, and intelligent. That's the promise of multi-agent systems, and it's time developers started paying attention.\n\n**Main Sections:**\n\n**1. Understanding the Multi-Agent Mindset:**\n\n*   **What exactly is a Multi-Agent System (MAS)?** Briefly explain the core concept of autonomous agents collaborating to achieve a common goal.\n*   **Beyond Simple Functions: The Power of Autonomy and Interaction.** Highlight how agents possess individual intelligence, can learn, and communicate with each other.\n*   **Think Collaboration, Not Just Code Blocks.** Draw an analogy to human teams working on complex projects.\n\n**2. Solving Real-World Development Pains with MAS:**\n\n*   **Enhanced Modularity and Maintainability:** Discuss how breaking down complex systems into smaller, specialized agents makes code easier to understand, debug, and update.\n*   **Improved Scalability and Resilience:** Explain how agents can be independently scaled and how the system can continue functioning even if some agents fail.\n*   **Intelligent Automation and Optimization:** Explore how agents can automate tedious tasks, adapt to changing conditions, and optimize resource utilization.\n\n**3. Practical Applications and Use Cases for Developers:**\n\n*   **Smart Code Generation and Refactoring:** Imagine agents that can suggest code improvements, automatically refactor legacy code, or even generate boilerplate based on specific requirements.\n*   **Automated Testing and Debugging:** Discuss how agents can autonomously identify bugs, generate test cases, and even propose fixes, significantly reducing testing cycles.\n*   **Complex System Orchestration and Management:** Explain how MAS can be used to manage distributed systems, microservices, and IoT networks with greater efficiency and intelligence.\n\n**4. Getting Started with Multi-Agent Development:**\n\n*   **Key Concepts and Architectures to Explore.** Briefly introduce popular MAS architectures like BDI (Belief-Desire-Intention) or agent communication languages (ACLs).\n*   **Tools and Frameworks for MAS Development.** Mention some existing libraries or platforms that facilitate MAS creation (e.g., JADE, NetLogo, or even custom implementations).\n*   **The Mindset Shift: Embracing Decentralization and Collaboration.** Emphasize the conceptual change required to think in terms of interacting agents.\n\n**Concluding Thought:** Multi-agent systems aren't just a futuristic concept; they are a powerful paradigm shift that can equip software developers with the tools to build more sophisticated, adaptable, and efficient software. By embracing this approach, you can move beyond traditional development methods and unlock a new level of innovation in your projects.\nWriterAgent > ## Level Up Your Code: How Multi-Agent Systems Can Revolutionize Software Development\n\nAre you tired of monolithic codebases that are a nightmare to manage and scale? Imagine a world where your software development process is more agile, robust, and intelligent. That's the promise of multi-agent systems (MAS), and it's time developers started paying attention.\n\nAt its core, a MAS is a collection of autonomous agents, each with its own intelligence, that collaborate to achieve a common goal. Think of it like a highly skilled human team working on a complex project, but composed of software entities. Unlike simple functions, these agents can learn, adapt, and communicate, making them far more powerful.\n\nThis \"multi-agent mindset\" directly tackles real-world development pains. By breaking down systems into smaller, specialized agents, you gain enhanced modularity and maintainability. Debugging a single agent is infinitely easier than sifting through a giant codebase. Furthermore, MAS offers improved scalability and resilience; individual agents can be scaled independently, and the system can often continue functioning even if some agents falter.\n\nThe practical applications are game-changing. Imagine agents that can automate code generation and refactoring, intelligently suggest improvements, or even autonomously discover and fix bugs. MAS can also streamline the orchestration of complex distributed systems, microservices, and IoT networks.\n\nGetting started involves exploring concepts like BDI (Belief-Desire-Intention) architectures and agent communication languages, alongside frameworks like JADE or NetLogo. The key is embracing a shift towards decentralization and collaboration. Multi-agent systems aren't just futuristic; they're a powerful paradigm shift ready to revolutionize how we build software.\nEditorAgent > ## Level Up Your Code: How Multi-Agent Systems Can Revolutionize Software Development\n\nAre you tired of wrestling with monolithic codebases that become increasingly difficult to manage and scale? Imagine a development process that is not only more agile and robust but also significantly more intelligent. This is the compelling promise of Multi-Agent Systems (MAS), and it's a paradigm shift that every forward-thinking developer should be exploring.\n\n### Understanding the Multi-Agent Mindset\n\nAt its heart, a Multi-Agent System is a collection of independent, autonomous agents. Each agent possesses its own intelligence, capable of learning, adapting, and making decisions. Crucially, these agents collaborate and communicate with each other to achieve a common, overarching goal. Think of it like a highly skilled human team working on a complex project, but instead of people, you have sophisticated software entities. Unlike simple functions or even traditional objects, these agents bring a level of dynamic interaction and independent problem-solving that unlocks new possibilities.\n\n### Solving Real-World Development Pains with MAS\n\nThe \"multi-agent mindset\" offers elegant solutions to many persistent challenges in software development:\n\n*   **Enhanced Modularity and Maintainability:** By decomposing complex systems into smaller, specialized agents, you achieve significantly improved modularity. Debugging and updating individual agents is far more manageable than navigating a sprawling, monolithic codebase. This leads to cleaner, more understandable, and easier-to-maintain systems.\n*   **Improved Scalability and Resilience:** MAS inherently supports better scalability. Individual agents can be scaled up or down independently based on demand, optimizing resource utilization. Furthermore, the system often exhibits greater resilience; if one agent encounters an issue or fails, the rest of the system can often continue to function, gracefully adapting to the disruption.\n*   **Intelligent Automation and Optimization:** The autonomous nature of agents allows for powerful automation. Imagine agents that can learn from system behavior, proactively identify potential issues, optimize resource allocation in real-time, or adapt to changing environmental conditions without explicit human intervention.\n\n### Practical Applications and Use Cases for Developers\n\nThe potential applications of MAS in software development are vast and transformative:\n\n*   **Smart Code Generation and Refactoring:** Envision agents that can intelligently analyze your codebase, suggest performance improvements, automatically refactor legacy code into more modern structures, or even generate boilerplate code based on high-level requirements.\n*   **Automated Testing and Debugging:** MAS can revolutionize testing and debugging. Agents could autonomously discover and pinpoint bugs, generate comprehensive test cases based on system behavior, and even propose or implement fixes, dramatically reducing development cycle times.\n*   **Complex System Orchestration and Management:** For distributed systems, microservices architectures, and the ever-growing realm of IoT networks, MAS offers intelligent orchestration. Agents can manage inter-service communication, monitor system health, and ensure efficient operation across complex, dynamic environments.\n\n### Getting Started with Multi-Agent Development\n\nEmbarking on the journey of multi-agent development involves exploring key concepts and adopting a new way of thinking. Familiarize yourself with architectures like **BDI (Belief-Desire-Intention)**, which models agent decision-making, and **Agent Communication Languages (ACLs)**, which define how agents interact. Frameworks such as **JADE** (Java Agent DEvelopment Framework) or **NetLogo** (primarily for simulation, but a good learning tool) can provide practical starting points. The most crucial step, however, is embracing a mindset shift towards decentralization and collaboration, thinking in terms of interacting, intelligent entities rather than just static code.\n\nMulti-agent systems are no longer just a futuristic concept; they represent a powerful paradigm shift. By embracing this approach, software developers can equip themselves with the tools to build more sophisticated, adaptable, efficient, and intelligent software, unlocking a new level of innovation in their projects.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:51:05.558447Z","iopub.execute_input":"2025-11-11T15:51:05.558728Z","iopub.status.idle":"2025-11-11T15:51:05.563918Z","shell.execute_reply.started":"2025-11-11T15:51:05.558712Z","shell.execute_reply":"2025-11-11T15:51:05.562954Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:51:10.548905Z","iopub.execute_input":"2025-11-11T15:51:10.549138Z","iopub.status.idle":"2025-11-11T15:51:10.553918Z","shell.execute_reply.started":"2025-11-11T15:51:10.549124Z","shell.execute_reply":"2025-11-11T15:51:10.553119Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:51:15.340710Z","iopub.execute_input":"2025-11-11T15:51:15.341001Z","iopub.status.idle":"2025-11-11T15:51:15.346658Z","shell.execute_reply.started":"2025-11-11T15:51:15.340976Z","shell.execute_reply":"2025-11-11T15:51:15.345394Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:51:26.707262Z","iopub.execute_input":"2025-11-11T15:51:26.707658Z","iopub.status.idle":"2025-11-11T15:51:26.713248Z","shell.execute_reply.started":"2025-11-11T15:51:26.707631Z","shell.execute_reply":"2025-11-11T15:51:26.712386Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:51:32.673992Z","iopub.execute_input":"2025-11-11T15:51:32.674296Z","iopub.status.idle":"2025-11-11T15:51:32.679996Z","shell.execute_reply.started":"2025-11-11T15:51:32.674280Z","shell.execute_reply":"2025-11-11T15:51:32.678907Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T15:51:38.000704Z","iopub.execute_input":"2025-11-11T15:51:38.000959Z","iopub.status.idle":"2025-11-11T15:51:43.864620Z","shell.execute_reply.started":"2025-11-11T15:51:38.000939Z","shell.execute_reply":"2025-11-11T15:51:43.863640Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nTechResearcher > **Key AI/ML Trends and Their Impact:**\n\n1.  **Generative AI and Complex Content Creation:** This trend sees AI creating sophisticated multimedia content like graphics, video, and music, expanding beyond text. Companies like Google (Imagen, Muse) and OpenAI are at the forefront. Its impact is revolutionary for artistic expression and practical applications across various industries.\n\n2.  **Shift from Large Language Models (LLMs) to Small Language Models (SLMs):** This development focuses on more efficient and specialized AI models. The impact is likely to be increased accessibility and tailored AI solutions for specific tasks.\n\n3.  **Ethical and Explainable AI:** With AI's growing influence, there's a strong push for transparent and unbiased models. This is crucial for building trust and understanding AI-driven decisions, especially in sensitive areas like finance and healthcare.\n\n**Key Companies Involved:** Major players include Google, Microsoft, NVIDIA, Apple, Meta, IBM, and OpenAI.\n\n**Potential Impact:** AI and ML are projected to drive significant economic growth, with the global AI market anticipated to reach over $800 billion by 2030. These technologies are transforming industries like healthcare (diagnosis, patient monitoring), finance (fraud detection, market analysis), and manufacturing (automation, predictive maintenance), enhancing efficiency, and creating new opportunities.\nFinanceResearcher > Here's a concise briefing on current fintech trends:\n\n**1. AI Integration:** Artificial intelligence is increasingly used for enhanced risk management, fraud detection, hyper-personalization of services, and operational automation. Market implications include improved efficiency and customer experiences, but also potential risks around data privacy and bias. The future outlook is for deeper AI adoption, with AI agents becoming more prevalent.\n\n**2. Embedded Finance:** Financial services are being seamlessly integrated into non-financial platforms. This trend offers market advantages like increased customer convenience, new revenue streams for businesses, and greater financial inclusion. The market is expected to grow significantly, with embedded payments and lending leading the way.\n\n**3. Decentralized Finance (DeFi):** DeFi continues to evolve, offering blockchain-based alternatives to traditional financial services. Market implications include increased accessibility, lower costs, and enhanced transparency, though regulatory uncertainty and security remain challenges. The future outlook points to greater interoperability, mainstream adoption, and the tokenization of real-world assets.\nHealthResearcher > **Health:**\n*   **CRISPR Gene Editing for Inherited Diseases:** Advancements in CRISPR technology have led to the first approvals for treating sickle cell anemia and beta-thalassemia. This holds immense promise for a wide range of genetic disorders, with ongoing research for conditions like blindness and certain cancers. Practical application is already here, with more complex genetic diseases expected to be treatable within 5-10 years.\n*   **AI in Medical Imaging:** Artificial intelligence is revolutionizing medical diagnostics, particularly in improving the accuracy of mammograms and detecting heart conditions. This integration promises earlier disease detection and more personalized treatment plans. Expect broader AI adoption across various imaging modalities within the next 2-5 years.\n*   **CAR T-Cell Therapy for Brain Cancer:** This immunotherapy, which reengineers a patient's own immune cells, is showing new hope for pediatric and adult brain cancer patients. While still in early stages for brain tumors, CAR T-cell therapy's success in blood cancers suggests significant advancements and wider application in oncology within the next 5-7 years.\n\n**Technology:**\n*   **Agentic AI:** Autonomous AI agents capable of independent task execution are emerging, with applications in areas like self-driving vehicles and robotic process automation. These systems aim to reduce human intervention and boost productivity. Widespread adoption is anticipated within 3-5 years.\n*   **Spatial Computing:** The convergence of physical and digital worlds through AR/VR, IoT, and AI is creating immersive experiences. Applications range from education and retail to AR-guided surgeries. The market is projected for substantial growth, with significant impact expected within the next 5-10 years.\n*   **Post-Quantum Cryptography (PQC):** As quantum computing advances, PQC is crucial for data security against future quantum decryption threats. Development is ongoing, with practical implementation and standardization expected within the next 5-7 years.\n\n**Finance:**\n*   **AI and Machine Learning in Risk Decisioning:** AI and ML are transforming financial services by enhancing risk assessment and user experience. This includes automating underwriting and enabling real-time decisions. Continued integration and sophistication are expected over the next 2-5 years.\n*   **Blockchain and DeFi:** Blockchain technology is creating decentralized and secure financial platforms, improving peer-to-peer lending, smart contracts, and fraud screening. Its role in streamlining processes and enhancing data reliability is growing, with broader adoption in the next 5-7 years.\n*   **Digital Bank Currencies (CBDCs):** The rise of central bank digital currencies is poised to reshape financial transactions. While still in development and pilot phases globally, widespread implementation could occur within the next 5-10 years.\nAggregatorAgent > ## Executive Summary: Tech, Health, and Finance Briefing\n\nArtificial intelligence (AI) is the unifying force across technology, health, and finance, driving transformative advancements and significant economic growth projected to exceed $800 billion by 2030. Generative AI is rapidly evolving beyond text to create complex multimedia content, while a strategic shift towards more efficient Small Language Models (SLMs) promises greater accessibility and tailored solutions. Crucially, ethical and explainable AI is paramount for building trust and understanding in sensitive applications.\n\nIn healthcare, AI is revolutionizing diagnostics through improved medical imaging and is poised to accelerate gene editing therapies like CRISPR for inherited diseases. Meanwhile, immunotherapy like CAR T-cell therapy offers new hope for complex cancers.\n\nFinance is leveraging AI for enhanced risk management, fraud detection, and personalized services, alongside the rise of embedded finance and decentralized platforms (DeFi) powered by blockchain. Emerging technologies like agentic AI and spatial computing are set to further integrate digital and physical realities, while advancements in post-quantum cryptography are crucial for future data security.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T16:10:56.130035Z","iopub.execute_input":"2025-11-11T16:10:56.130415Z","iopub.status.idle":"2025-11-11T16:10:56.137316Z","shell.execute_reply.started":"2025-11-11T16:10:56.130389Z","shell.execute_reply":"2025-11-11T16:10:56.136218Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T16:10:58.501558Z","iopub.execute_input":"2025-11-11T16:10:58.501795Z","iopub.status.idle":"2025-11-11T16:10:58.508186Z","shell.execute_reply.started":"2025-11-11T16:10:58.501780Z","shell.execute_reply":"2025-11-11T16:10:58.506841Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T16:11:23.192102Z","iopub.execute_input":"2025-11-11T16:11:23.192354Z","iopub.status.idle":"2025-11-11T16:11:23.197077Z","shell.execute_reply.started":"2025-11-11T16:11:23.192339Z","shell.execute_reply":"2025-11-11T16:11:23.196387Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T16:11:57.106085Z","iopub.execute_input":"2025-11-11T16:11:57.106350Z","iopub.status.idle":"2025-11-11T16:11:57.112300Z","shell.execute_reply.started":"2025-11-11T16:11:57.106331Z","shell.execute_reply":"2025-11-11T16:11:57.110857Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T16:12:16.766501Z","iopub.execute_input":"2025-11-11T16:12:16.766854Z","iopub.status.idle":"2025-11-11T16:12:16.772353Z","shell.execute_reply.started":"2025-11-11T16:12:16.766835Z","shell.execute_reply":"2025-11-11T16:12:16.771709Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T16:12:22.977789Z","iopub.execute_input":"2025-11-11T16:12:22.978089Z","iopub.status.idle":"2025-11-11T16:12:31.144927Z","shell.execute_reply.started":"2025-11-11T16:12:22.978073Z","shell.execute_reply":"2025-11-11T16:12:31.144153Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > The salty air always tasted of stories, but Elias never expected one to arrive by map. It washed ashore one tempestuous Tuesday, a tightly rolled parchment smelling faintly of brine and something else‚Ä¶ ozone? Unfurling it by the lamplight, Elias gasped. The paper wasn't paper at all, but some supple, leathery material. And it glowed. Not with a steady, lamp-like luminescence, but with an internal, pulsing light, tracing out islands and currents he‚Äôd never seen on any chart. The symbols were alien, intricate whorls that seemed to writhe under his gaze. A single, burning X marked a spot in the uncharted Obsidian Sea, a place sailors whispered was cursed. Elias, a man of routine and order, felt a strange tremor of adventure run through his weathered bones.\nCriticAgent > The plot is intriguing and sets up a clear hook for an adventure. However, it feels like the very beginning of a story rather than a complete narrative.\n\nHere are a few suggestions for improvement:\n\n*   **Develop Elias's Character:** While Elias is described as a \"man of routine and order,\" we don't see enough of this to understand the impact the map has on him. Show, don't just tell, his hesitation or his internal conflict between his structured life and the pull of the unknown. For example, how does his routine get disrupted by this discovery? Does he try to rationalize it away at first?\n*   **Expand on the Map's Mystery:** The description of the map is evocative, but the \"alien\" symbols and \"pulsing light\" could be further explored. What does Elias *think* they might mean, even if he can't decipher them? Does the ozone smell suggest a connection to storms or something supernatural? These details can deepen the mystery and Elias's fascination.\n*   **Introduce a Consequence or Decision:** The story ends with Elias feeling a \"tremor of adventure.\" To make it more complete, the narrative should move towards his first decision or action related to the map. Does he try to research it? Does he dismiss it and then it reappears? Does he immediately start planning an expedition, however tentatively? This would give the current excerpt a sense of progression towards a story arc.\nRefinerAgent > The salty air always tasted of stories, but Elias, a man whose life was as meticulously ordered as the lighthouse beam he tended, never expected one to arrive by map. His days were a symphony of predictable tasks: the morning polish of the Fresnel lens, the mid-day logbook entry, the evening winding of the clockwork mechanism. Even the storms, when they raged, were merely variations on a theme he understood. But this Tuesday tempest was different. It brought with it a tightly rolled parchment, smelling not just of brine, but of an acrid, electric tang ‚Äì ozone, like the air after a lightning strike.\n\nElias‚Äôs routine faltered the moment he unfurled the map by the steady glow of his oil lamp. His calloused fingers, accustomed to the smooth glass of the lens and the rough texture of rope, trembled as they touched the strange material. It wasn't paper; it was supple, leathery, and alive with an internal, pulsing light. It traced islands and currents unknown to any chart in his possession, a cartographical phantom. The symbols etched upon it were unlike any language he‚Äôd ever encountered, intricate whorls that seemed to writhe, to *breathe*, under his gaze. Elias, a man who charted his life by the predictable rhythm of the tides, felt a disorienting lurch. He tried to dismiss the map, to rationalize the strange light as a trick of the lamplight, the ozone smell a mere byproduct of the storm. Yet, a single, burning 'X' pulsed at the heart of the uncharted Obsidian Sea, a place whispered to be cursed, a place no sane sailor would venture. The map hummed with a silent invitation, a siren song to his ordered soul. He found himself tracing the alien symbols, a flicker of what felt like recognition, or perhaps just desperate hope, warring with his ingrained caution. He looked from the glowing parchment to the familiar, comforting sweep of the lighthouse beam, then back to the map. The tremor that ran through his weathered bones wasn't just adventure; it was the tremor of a man standing at the precipice of his own carefully constructed world, contemplating a step into the utterly unknown. He carefully rolled the map, the pulsing light still visible through the leathery folds, and placed it not in his logbook, but in a sea chest, a chest that had remained closed for twenty years. The decision hadn't been made, not consciously, but a seed had been sown in the fertile ground of Elias‚Äôs ordered existence, a seed that promised to bloom into something wild and unpredictable.\nCriticAgent > APPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}